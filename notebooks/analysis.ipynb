{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex, unicodedata\n",
    "class SimpleTokenizer(object):\n",
    "    ALPHA_NUM = r'[\\p{L}\\p{N}\\p{M}]+'\n",
    "    NON_WS = r'[^\\p{Z}\\p{C}]'\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            annotators: None or empty set (only tokenizes).\n",
    "        \"\"\"\n",
    "        self._regexp = regex.compile(\n",
    "            '(%s)|(%s)' % (self.ALPHA_NUM, self.NON_WS),\n",
    "            flags=regex.IGNORECASE + regex.UNICODE + regex.MULTILINE\n",
    "        )\n",
    "\n",
    "    def tokenize(self, text, uncased=False):\n",
    "        matches = [m for m in self._regexp.finditer(text)]\n",
    "        if uncased:\n",
    "            tokens = [m.group().lower() for m in matches]\n",
    "        else:\n",
    "            tokens = [m.group() for m in matches]\n",
    "        return tokens\n",
    "\n",
    "def has_answer(answers: list[str], text, tokenizer) -> bool:\n",
    "    \"\"\"Check if a document contains an answer string.\"\"\"\n",
    "    text = _normalize(text)\n",
    "    text = tokenizer.tokenize(text, uncased=True)\n",
    "\n",
    "    for answer in answers:\n",
    "        answer = _normalize(answer)\n",
    "        answer = tokenizer.tokenize(answer, uncased=True)\n",
    "        for i in range(0, len(text) - len(answer) + 1):\n",
    "            if answer == text[i: i + len(answer)]:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def _normalize(text):\n",
    "    return unicodedata.normalize('NFD', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/data/seongilpark/research/in-context-robust-ralm/data/unans.csv\")\n",
    "zero = pd.read_csv(\"/data/seongilpark/research/in-context-robust-ralm/data/zero.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasanswer(ctxs) -> bool:\n",
    "    return any([c[\"hasanswer\"] for c in ctxs])\n",
    "\n",
    "def answerable(ctxs) -> bool:\n",
    "    res = []\n",
    "    for ctx in ctxs:\n",
    "        hasanswer, entail = ctx[\"hasanswer\"], ctx[\"nli\"]\n",
    "        if hasanswer and (entail in [\"entailment\", \"contradiction\"]):\n",
    "            res.append(\"answerable\")\n",
    "        elif (not hasanswer) and (entail != \"entailment\"):\n",
    "            res.append(\"unanswerable\")\n",
    "        else:\n",
    "            res.append(\"uncertain\")\n",
    "    if res.count(\"answerable\") >= 1:\n",
    "        return \"answerable\"\n",
    "    elif res.count(\"unanswerable\") == 5:\n",
    "        return \"unanswerable\"\n",
    "    else:\n",
    "        return \"uncertain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Atipico1/incontext_nq\")[\"train\"]\n",
    "dataset = dataset.map(lambda x: {\"ctxs\":x[\"ctxs\"][:5]})\n",
    "dataset = dataset.map(lambda x: {\"answerable\":answerable(x[\"ctxs\"])})\n",
    "dataset = dataset.filter(lambda x: x[\"answerable\"] == \"answerable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answerable\n",
      "uncertain       632\n",
      "answerable      255\n",
      "unanswerable    113\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.DataFrame(dataset)\n",
    "dataset[\"answerable\"] = dataset[\"ctxs\"].apply(lambda x: answerable(x))\n",
    "print(dataset.answerable.value_counts())\n",
    "df[\"answerable\"] = dataset[\"answerable\"].tolist()\n",
    "zero[\"answerable\"] = dataset[\"answerable\"].tolist()\n",
    "df[\"answers\"] = dataset[\"answers\"]\n",
    "zero[\"answers\"] = dataset[\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_unans\"] = df[\"pred\"].apply(lambda x: \"unanswerable\" in x.lower())\n",
    "zero[\"is_unans\"] = zero[\"pred\"].apply(lambda x: \"unanswerable\" in x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_unans_zero\"] = zero[\"is_unans\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df.is_unans == df.is_unans_zero) & (df.is_unans == True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df.is_unans != df.is_unans_zero) & (df.is_unans == True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4247787610619469\n",
      "0.37168141592920356\n"
     ]
    }
   ],
   "source": [
    "for data in [df, zero]:\n",
    "    total = data[data.answerable==\"unanswerable\"].shape[0]\n",
    "    sub = data[(data.answerable==\"unanswerable\") & (data.is_unans == True)].shape[0]\n",
    "    print(sub/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42745098039215684\n",
      "0.4196078431372549\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizer()\n",
    "df[\"acc\"] = df.apply(lambda x: has_answer(x[\"answers\"], x[\"pred\"], tokenizer), axis=1)\n",
    "zero[\"acc\"] = zero.apply(lambda x: has_answer(x[\"answers\"], x[\"pred\"], tokenizer), axis=1)\n",
    "for data in [df, zero]:\n",
    "    total = data[data.answerable==\"answerable\"].shape[0]\n",
    "    sub = data[(data.answerable==\"answerable\") & (data.acc == True)].shape[0]\n",
    "    print(sub/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29312288613303267\n",
      "0.28410372040586246\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizer()\n",
    "df[\"acc\"] = df.apply(lambda x: has_answer(x[\"answers\"], x[\"pred\"], tokenizer), axis=1)\n",
    "zero[\"acc\"] = zero.apply(lambda x: has_answer(x[\"answers\"], x[\"pred\"], tokenizer), axis=1)\n",
    "for data in [df, zero]:\n",
    "    total = data[data.answerable!=\"unanswerable\"].shape[0]\n",
    "    sub = data[(data.answerable!=\"unanswerable\") & (data.acc == True)].shape[0]\n",
    "    print(sub/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
